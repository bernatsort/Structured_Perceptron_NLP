{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1: *Part Of Speech* usando un Perceptrón Estructurado\n",
    "\n",
    "En este primer ejercicio se pide construir un perceptron estructurado y entrenarlo para hacer una predicción de *Part Of Speech* usando el dataset [CoNLL-2003](https://paperswithcode.com/dataset/conll-2003). Es un dataset que contiene secuencias de frases en ingles extraídas de libros y la entidad de cada palabra (nombre, vervo, determinante, etc.) correspondiente al POS.\n",
    "\n",
    "\n",
    "## Enunciado:\n",
    "\n",
    "#### 1. Entrenar un perpectrón estructurado para predecir Part Of Speech usando el dataset ConLL.\n",
    "\n",
    "Además, responder a las siguientes preguntas:\n",
    "\n",
    "* 1.1. ¿Cuantos features tiene el feature mapper? ¿Qué representan?\n",
    "* 1.2. En una seucencia de entrenamiento, ¿cuandos tipos de features encontramos en una secuencia? ¿Qué nos indican?\n",
    "* 1.3. Cuando construimos el SP, ¿cuantos estados posibles tiene y porqué?\n",
    "* 1.4. Cuando construimos el SP, ¿cuantos parámetros tiene y porqué?\n",
    "\n",
    "\n",
    "#### 2. Comparar los resultados con el HMM entrenado con el mismo dataset usado en la sesión 2 en clase.\n",
    "\n",
    "\n",
    "#### 3. Comprovar si el perceptrón estructurado clasifica correctamente una palabra que no ha visto en el entrenamiento.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part Of Speech (POS)**\n",
    "\n",
    "- Part Of Speech (POS) se refiere a la categoría gramatical o función sintáctica que desempeña una palabra en una frase. \n",
    "- Es un concepto lingüístico utilizado para clasificar las palabras en función de sus propiedades sintácticas y morfológicas. \n",
    "- El etiquetado POS consiste en asignar una etiqueta específica a cada palabra de una frase.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skseq\n",
    "import skseq.sequences\n",
    "from skseq.sequences import sequence\n",
    "import skseq.readers\n",
    "import skseq.readers.pos_corpus\n",
    "\n",
    "\n",
    "\n",
    "# To import modules or packages that are located in a directory above the current script's directory\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read and handle part-of-speech tagging datasets\n",
    "corpus = skseq.readers.pos_corpus.PostagCorpus()\n",
    "\n",
    "# path to the directory where the CoNLL-2003 dataset is stored\n",
    "data_path = \"conll\"\n",
    "\n",
    "# train_seq: a list of sequences where each sequence represents a sentence in the training data, \n",
    "            # and each word in the sentence is paired with its corresponding part-of-speech tag.\n",
    "    # read_sequence_list_conll method: to read the training data from the CoNLL-2003 dataset\n",
    "    # max_sent_len: An optional argument that specifies the maximum sentence length to consider. In this case, it is set to 100.\n",
    "    # max_nr_sent: An optional argument that specifies the maximum number of sentences to read. Here, it is set to 5000.\n",
    "train_seq = corpus.read_sequence_list_conll(data_path + \"/train-02-21.conll\", max_sent_len=100, max_nr_sent=5000)\n",
    "\n",
    "test_seq = corpus.read_sequence_list_conll(data_path + \"/test-23.conll\", max_sent_len=100, max_nr_sent=1000)\n",
    "\n",
    "# dev_seq: a list of sequences representing the development sentences along with their corresponding part-of-speech tags.\n",
    "dev_seq = corpus.read_sequence_list_conll(data_path + \"/dev-22.conll\", max_sent_len=100, max_nr_sent=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0/0 1/1 2/2 3/3 4/2 5/0 6/4 7/1 8/2 9/4 10/0 11/2 12/5 13/2 14/2 15/4 6/4 16/6 17/2 18/6 19/1 20/2 21/0 22/2 23/2 24/4 9/4 25/2 26/7 27/2 28/4 24/4 19/1 29/2 5/0 30/2 24/4 31/6 32/0 33/2 34/2 24/4 35/6 36/8 37/6 38/5 39/2 40/2 41/4 "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primera secuencia de los datos de entrenamiento.\n",
    "- Cada token de la secuencia se representa como 'word_index/tag_index', donde 'word_index' es el índice de la palabra en la frase y 'tag_index' es el índice de la part-of-speech tag correspondiente a esa palabra. \n",
    "- Por ejemplo, '0/0' indica que la primera palabra de la frase tiene asignada la part-of-speech tag con índice 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adp': 0,\n",
       " 'det': 1,\n",
       " 'noun': 2,\n",
       " 'num': 3,\n",
       " '.': 4,\n",
       " 'prt': 5,\n",
       " 'verb': 6,\n",
       " 'conj': 7,\n",
       " 'adv': 8,\n",
       " 'pron': 9,\n",
       " 'adj': 10,\n",
       " 'x': 11}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.y_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diccionario 'train_seq.y_dict' representa el diccionario que asigna part-of-speech tags a sus índices numéricos correspondientes. A cada part-of-speech tag se le asigna un índice único con fines de representación y cálculo en el modelo.\n",
    "\n",
    "En el diccionario proporcionado tenemos lo siguiente: \n",
    "\n",
    "- 'adp': 0 representa la part-of-speech tag \"adp\" (preposición).\n",
    "- 'det': 1 representa la part-of-speech tag \"det\" (determinante).\n",
    "- 'noun': 2 representa la part-of-speech tag \"noun\" (sustantivo).\n",
    "- 'num': 3 representa la parte de la etiqueta \"num\" (numeral).\n",
    "- '.': 4 representa la part-of-speech tag '.' (signo de puntuación).\n",
    "- 'prt': 5 representa la part-of-speech tag \"prt\" (partícula).\n",
    "- 'verb': 6 representa la part-of-speech tag \"verb\" (verbo).\n",
    "- 'conj': 7 representa la part-of-speech tag \"conj\" (conjunción).\n",
    "- 'adv': 8 representa la part-of-speech tag \"adv\" (adverbio).\n",
    "- 'pron': 9 representa la part-of-speech tag \"pron\" (pronombre).\n",
    "- 'adj': 10 representa la part-of-speech tag \"adj\" (adjetivo).\n",
    "- 'x': 11 representa la part-of-speech tag \"x\" (otro).\n",
    "\n",
    "Este diccionario permite una correspondencia eficaz entre las etiquetas y sus representaciones numéricas durante el entrenamiento y la evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<skseq.sequences.id_feature.IDFeatures at 0x11af1e0d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
