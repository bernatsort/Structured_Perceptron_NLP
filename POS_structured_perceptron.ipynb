{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Part Of Speech* usando un Perceptrón Estructurado\n",
    "\n",
    "Construir un perceptron estructurado y entrenarlo para hacer una predicción de *Part Of Speech* usando el dataset [CoNLL-2003](https://paperswithcode.com/dataset/conll-2003). Es un dataset que contiene secuencias de frases en ingles extraídas de libros y la entidad de cada palabra (nombre, vervo, determinante, etc.) correspondiente al POS.\n",
    "\n",
    "\n",
    "## Objetivos:\n",
    "\n",
    "#### 1. Entrenar un perceptrón estructurado para predecir Part Of Speech usando el dataset ConLL.\n",
    "\n",
    "Además, responder a las siguientes preguntas:\n",
    "\n",
    "* 1.1. ¿Cuántos features tiene el feature mapper? ¿Qué representan?\n",
    "* 1.2. En una secuencia de entrenamiento, ¿cuántos tipos de features encontramos en una secuencia? ¿Qué nos indican?\n",
    "* 1.3. Cuando construimos el SP, ¿cuántos estados posibles tiene y por qué?\n",
    "* 1.4. Cuando construimos el SP, ¿cuántos parámetros tiene y por qué?\n",
    "\n",
    "\n",
    "#### 2. Comparar los resultados con el HMM entrenado con el mismo dataset usado en la sesión 2 en clase.\n",
    "\n",
    "\n",
    "#### 3. Comprovar si el perceptrón estructurado clasifica correctamente una palabra que no ha visto en el entrenamiento.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part Of Speech (POS)**\n",
    "\n",
    "- Part Of Speech (POS) se refiere a la categoría gramatical o función sintáctica que desempeña una palabra en una frase. \n",
    "- Es un concepto lingüístico utilizado para clasificar las palabras en función de sus propiedades sintácticas y morfológicas. \n",
    "- El etiquetado POS consiste en asignar una etiqueta específica a cada palabra de una frase.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "import numpy as np\n",
    "import skseq\n",
    "import skseq.sequences\n",
    "from skseq.sequences import sequence\n",
    "import skseq.readers\n",
    "import skseq.readers.pos_corpus\n",
    "import skseq.sequences.structured_perceptron as spc\n",
    "\n",
    "# To import modules or packages that are located in a directory above the current script's directory\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read and handle part-of-speech tagging datasets\n",
    "corpus = skseq.readers.pos_corpus.PostagCorpus()\n",
    "\n",
    "# path to the directory where the CoNLL-2003 dataset is stored\n",
    "data_path = \"conll\"\n",
    "\n",
    "# train_seq: a list of sequences where each sequence represents a sentence in the training data, \n",
    "            # and each word in the sentence is paired with its corresponding part-of-speech tag.\n",
    "    # read_sequence_list_conll method: to read the training data from the CoNLL-2003 dataset\n",
    "    # max_sent_len: An optional argument that specifies the maximum sentence length to consider. \n",
    "                    # In this case, it is set to 100.\n",
    "    # max_nr_sent: An optional argument that specifies the maximum number of sentences to read. \n",
    "                   # Here, it is set to 5000.\n",
    "train_seq = corpus.read_sequence_list_conll(data_path + \"/train-02-21.conll\", \n",
    "                                            max_sent_len=100, \n",
    "                                            max_nr_sent=5000)\n",
    "\n",
    "test_seq = corpus.read_sequence_list_conll(data_path + \"/test-23.conll\", \n",
    "                                           max_sent_len=100, \n",
    "                                           max_nr_sent=1000)\n",
    "\n",
    "# dev_seq: a list of sequences representing the development sentences along with their \n",
    "           # corresponding part-of-speech tags.\n",
    "dev_seq = corpus.read_sequence_list_conll(data_path + \"/dev-22.conll\", \n",
    "                                          max_sent_len=100, \n",
    "                                          max_nr_sent=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0/0 1/1 2/2 3/3 4/2 5/0 6/4 7/1 8/2 9/4 10/0 11/2 12/5 13/2 14/2 15/4 6/4 16/6 17/2 18/6 19/1 20/2 21/0 22/2 23/2 24/4 9/4 25/2 26/7 27/2 28/4 24/4 19/1 29/2 5/0 30/2 24/4 31/6 32/0 33/2 34/2 24/4 35/6 36/8 37/6 38/5 39/2 40/2 41/4 "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Primera secuencia de los datos de entrenamiento.\n",
    "- Cada token de la secuencia se representa como 'word_index/tag_index', donde 'word_index' es el índice de la palabra en la frase y 'tag_index' es el índice de la part-of-speech tag correspondiente a esa palabra. \n",
    "- Por ejemplo, '0/0' indica que la primera palabra de la frase tiene asignada la part-of-speech tag con índice 0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adp': 0,\n",
       " 'det': 1,\n",
       " 'noun': 2,\n",
       " 'num': 3,\n",
       " '.': 4,\n",
       " 'prt': 5,\n",
       " 'verb': 6,\n",
       " 'conj': 7,\n",
       " 'adv': 8,\n",
       " 'pron': 9,\n",
       " 'adj': 10,\n",
       " 'x': 11}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_seq.y_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El diccionario `train_seq.y_dict` representa el diccionario que asigna part-of-speech tags a sus índices numéricos correspondientes. A cada part-of-speech tag se le asigna un índice único con fines de representación y cálculo en el modelo.\n",
    "\n",
    "En el diccionario proporcionado tenemos lo siguiente: \n",
    "\n",
    "- 'adp': 0 representa la part-of-speech tag \"adp\" (preposición).\n",
    "- 'det': 1 representa la part-of-speech tag \"det\" (determinante).\n",
    "- 'noun': 2 representa la part-of-speech tag \"noun\" (sustantivo).\n",
    "- 'num': 3 representa la parte de la etiqueta \"num\" (numeral).\n",
    "- '.': 4 representa la part-of-speech tag '.' (signo de puntuación).\n",
    "- 'prt': 5 representa la part-of-speech tag \"prt\" (partícula).\n",
    "- 'verb': 6 representa la part-of-speech tag \"verb\" (verbo).\n",
    "- 'conj': 7 representa la part-of-speech tag \"conj\" (conjunción).\n",
    "- 'adv': 8 representa la part-of-speech tag \"adv\" (adverbio).\n",
    "- 'pron': 9 representa la part-of-speech tag \"pron\" (pronombre).\n",
    "- 'adj': 10 representa la part-of-speech tag \"adj\" (adjetivo).\n",
    "- 'x': 11 representa la part-of-speech tag \"x\" (otro).\n",
    "\n",
    "Este diccionario permite una correspondencia eficaz entre las etiquetas y sus representaciones numéricas durante el entrenamiento y la evaluación del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<skseq.sequences.id_feature.IDFeatures at 0x120114ee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_mapper = skseq.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La clase `IDFeatures` se encarga de asignar las secuencias de palabras de entrada y sus part-of-speech tags a un conjunto de características que utilizará el modelo de ML, como el perceptrón, para realizar predicciones. Estas características capturan información relevante sobre los datos de entrada que puede ayudar en la tarea de predicción.\n",
    "\n",
    "- Al inicializar `IDFeatures` con los datos de `train_seq`, el feature mapper analiza las secuencias de entrenamiento y extrae de ellas las características necesarias. Examina cada palabra de las secuencias y genera una representación de características basada en varias propiedades lingüísticas, como la propia palabra, sus palabras vecinas, su posición en la frase y otra información contextual.\n",
    "\n",
    "- El objeto `feature_mapper` sirve de puente entre las secuencias de entrada y el modelo de ML, permitiendo al modelo acceder a las características extraídas durante el entrenamiento o la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_mapper.build_features()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `build_features()`: construir la representación de características para las secuencias de entrada.\n",
    "- Al llamar a `build_features()`, el objeto `feature_mapper` procesa las secuencias de entrenamiento y prepara la representación de características, que se utilizará durante el entrenamiento y la predicción para proporcionar la información necesaria al modelo de aprendizaje automático.\n",
    "\n",
    "- Por tanto, `feature_mapper.build_features()` desencadena la construcción de la representación de características para las secuencias de entrada, permitiendo al modelo aprender y hacer predicciones basadas en las características extraídas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15377"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Número de características únicas que han sido extraídas y almacenadas \n",
    "# en el atributo `feature_dict` del objeto `feature_mapper`.\n",
    "len(feature_mapper.feature_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. Cuántos features tiene el feature mapper y qué representan:**\n",
    "-  Durante el proceso de construcción de características, el `feature_mapper` analiza las secuencias de entrada e identifica diferentes patrones, propiedades o información contextual que pueden ser utilizados como características para el modelo de aprendizaje automático. A cada característica se le asigna un índice numérico y se almacena en el `feature_dict`.\n",
    "\n",
    "- Evaluando `len(feature_mapper.feature_dict)`, se obtiene el recuento de características únicas que se han extraído de las secuencias de entrenamiento. En este caso 15377, lo que indica que hay 15377 características distintas que serán utilizadas por el modelo para el entrenamiento y la predicción.\n",
    "\n",
    "- Contar con un mayor número de características permite al modelo captar detalles más precisos y mejorar potencialmente su rendimiento. Sin embargo, también puede aumentar la complejidad computacional y requerir más datos para generalizar eficazmente. Por lo tanto, lograr un equilibrio entre el número de características y los datos disponibles es crucial en las tareas de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['init_tag:adp', 'id:In::adp', 'id:an::det', 'prev_tag:adp::det', 'id:Oct.::noun', 'prev_tag:det::noun', 'id:19::num', 'prev_tag:noun::num', 'id:review::noun', 'prev_tag:num::noun']\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(feature_mapper.feature_dict)\n",
    "print(feature_list[:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `feature_list` contiene todas las características únicas extraídas de las secuencias de entrenamiento.\n",
    "- 10 primeros elementos de la lista `feature_list`.\n",
    "- Cada característica sigue un formato específico, que suele constar de una o varias partes separadas por dos puntos (`:`):\n",
    "\n",
    "    - `init_tag:adp`: la secuencia comienza con una palabra etiquetada como una preposición.\n",
    "\n",
    "    - `id:In::adp`: la palabra \"In\" es etiquetada como una preposición.\n",
    "\n",
    "    - `prev_tag:adp::det`: la palabra actual es un determinante y la palabra anterior es una preposición. \n",
    "\n",
    "    - `id:oct.::noun`: la palabra \"oct.\" es etiquetada como un sustantivo.\n",
    "\n",
    "    - `prev_tag:det::noun`: la palabra actual es un sustantivo y la palabra anterior es un determinante.  \n",
    "\n",
    "    - `id:19::num`: el número \"19\" está etiquetado como un número en la secuencia. \n",
    "\n",
    "    - `prev_tag:noun::num`: la palabra actual es un número y la palabra anterior es un sustantivo.\n",
    "\n",
    "    - `id:review::noun`: la palabra \"review\" es etiquetada como un sustantivo. \n",
    "\n",
    "    - `prev_tag:num::noun`: la palabra actual es un sustantivo y la anterior un número. \n",
    "\n",
    "- Estas características están diseñadas para capturar distintos aspectos de los datos de entrada que son relevantes para la tarea de etiquetado de la part-of-speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'final_prev_tag', 'id', 'init_tag', 'prev_tag'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x.split(\":\")[0] for x in feature_mapper.feature_dict.keys()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtenemos un conjunto de las partes iniciales de las claves en el diccionario `feature_mapper.feature_dict`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. En una secuencia de entrenamiento, ¿cuántos tipos de features encontramos en una secuencia? ¿Qué nos indican?**\n",
    "\n",
    "En una secuencia de entrenamiento obtenemomos 4 tipos de features: \n",
    "\n",
    "- `final_prev_tag`: representa la última etiqueta de POS previa en una secuencia.\n",
    "\n",
    "- `id`: identificador de una palabra específica.\n",
    "\n",
    "- `init_tag`: representa la etiqueta de POS inicial de una secuencia.\n",
    "\n",
    "- `prev_tag`: representa la etiqueta de POS previa o anterior de una palabra en la secuencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features:    [[0]]\n",
      "Transition features: [[3], [5], [7], [9], [11], [13], [15], [5], [18], [20], [22], [24], [26], [28], [18], [30], [32], [34], [36], [38], [5], [11], [22], [28], [18], [30], [45], [47], [49], [18], [30], [15], [5], [11], [22], [18], [32], [55], [22], [28], [18], [32], [60], [62], [64], [26], [28], [18]]\n",
      "Final features:      [[68]]\n",
      "Emission features:   [[1], [2], [4], [6], [8], [10], [12], [14], [16], [17], [19], [21], [23], [25], [27], [29], [12], [31], [33], [35], [37], [39], [40], [41], [42], [43], [17], [44], [46], [48], [50], [43], [37], [51], [10], [52], [43], [53], [54], [56], [57], [43], [58], [59], [61], [63], [65], [66], [67]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Initial features:   \",     feature_mapper.feature_list[0][0])\n",
    "print (\"Transition features:\",  feature_mapper.feature_list[0][1])\n",
    "print (\"Final features:     \",       feature_mapper.feature_list[0][2])\n",
    "print (\"Emission features:  \",    feature_mapper.feature_list[0][3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Características que capturan la información relacionada con el estado inicial, las transiciones, el estado final y las emisiones en el modelo de perceptrón estructurado para el etiquetado de POS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento del perceptrón estructurado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos de entrada o entrenamiento\n",
    "trainx = train_seq.x_dict\n",
    "# etiquetas de salida de entrenamiento\n",
    "trainy = train_seq.y_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Diccionarios para obtener las representaciones numéricas de las secuencias de entrada (x) y las etiquetas de POS correspondientes (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instancio perceptrón estructurado\n",
    "sp = spc.StructuredPerceptron(trainx, \n",
    "                              trainy, \n",
    "                              feature_mapper) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 16937)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.get_num_states(), sp.get_num_observations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3. Cuando construimos el SP, ¿cuántos estados posibles tiene y por qué?**\n",
    "-  Hay 12 estados posibles en el modelo del perceptrón estructurado, por tanto, hay 12 posibles etiquetas de POS en el modelo, como hemos visto anteriormente.\n",
    "- Además, hay 16937 posibles características (observaciones) que el modelo puede tener en cuenta durante el entrenamiento y la inferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15377"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# número total de características en el feature mapper\n",
    "feature_mapper.get_num_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15377"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sp.parameters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4. Cuando construimos el SP, ¿cuántos parámetros tiene y por qué?**\n",
    "- Cuando construimos el perceptrón estructurado (SP), tiene un total de 15377 parámetros. Esto se debe a que cada característica en el feature mapper contribuye con un parámetro en el modelo.\n",
    "- El número de parámetros coincide con el número de características en el feature mapper.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_corpus(sequences, sequences_predictions):\n",
    "    total = 0.0\n",
    "    correct = 0.0\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        pred = sequences_predictions[i]\n",
    "        for j, y_hat in enumerate(pred.y):\n",
    "            if sequence.y[j] == y_hat:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "    return correct / total # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificación Viterbi en las secuencias de train y test.\n",
    "# Genera secuencias de predicciones (pred_train y pred_test) \n",
    "# utilizando el modelo de perceptrón estructurado. \n",
    "pred_train = sp.viterbi_decode_corpus(train_seq)\n",
    "pred_test = sp.viterbi_decode_corpus(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.103 \tTest acc: 0.105\n"
     ]
    }
   ],
   "source": [
    "# Evaluamos las secuencias de train y test utilizando las secuencias de predicciones generadas. \n",
    "# Los resultados de evaluación se almacenan en las variables eval_train y eval_test, respectivamente.\n",
    "eval_train = evaluate_corpus(train_seq.seq_list, pred_train)\n",
    "eval_test = evaluate_corpus(test_seq.seq_list, pred_test)\n",
    "print(\"Train accuracy: %.3f \\tTest accuracy: %.3f\"%(eval_train, eval_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ambas accuracy son bajas, lo que indica que el modelo actual tiene un rendimiento deficiente en la tarea de etiquetado de POS en estos conjuntos de datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo durante 4 epochs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.822854\n",
      "Epoch: 1 Accuracy: 0.904985\n",
      "Epoch: 2 Accuracy: 0.925024\n",
      "Epoch: 3 Accuracy: 0.937884\n",
      "CPU times: user 50.3 s, sys: 229 ms, total: 50.6 s\n",
      "Wall time: 50.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 4\n",
    "sp.fit(feature_mapper.dataset, num_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La accuracy aumenta a medida que avanzan las epochs, lo que indica que el modelo está mejorando su rendimiento en la tarea de etiquetado de POS. La accuracy inicial es del 82% en la primera epoch y alcanza alrededor del 94% en la cuarta epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secuencias de etiquetas predichas por el modelo \n",
    "# para cada secuencia de entrada en los conjuntos de train y test.\n",
    "pred_train = sp.viterbi_decode_corpus(train_seq)\n",
    "pred_test = sp.viterbi_decode_corpus(test_seq)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Después de entrenar el modelo de perceptrón estructurado, se utilizan las funciones `viterbi_decode_corpus()` para realizar la decodificación Viterbi en las secuencias de entrenamiento (train_seq) y prueba (test_seq). Estas funciones aplican el algoritmo de Viterbi para encontrar la secuencia de etiquetas más probable para cada secuencia de entrada, utilizando el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.921 \tTest acc: 0.889\n"
     ]
    }
   ],
   "source": [
    "# Calculamos la accuracy del modelo utilizando la función evaluate_corpus()\n",
    "eval_train = evaluate_corpus(train_seq.seq_list, pred_train)\n",
    "eval_test = evaluate_corpus(test_seq.seq_list, pred_test)\n",
    "print(\"Train acc: %.3f \\tTest acc: %.3f\"%(eval_train, eval_test))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La accuracy del modelo es del 92% en el conjunto de entrenamiento y 89% en el conjunto de prueba. \n",
    "- Esto indica que el modelo tiene un buen rendimiento en la tarea de etiquetado de POS."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Comparar los resultados con el HMM entrenado con el mismo dataset usado en la sesión 2 en clase.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados del modelo de perceptrón estructurado son diferentes de los resultados del modelo HMM entrenado con el mismo dataset.\n",
    "\n",
    "Para el modelo de perceptrón estructurado, la accuracy en el conjunto de entrenamiento es del 92% y en el conjunto de prueba es del 89%.\n",
    "\n",
    "En cambio, para el modelo HMM, la accuracy en el conjunto de entrenamiento y prueba es del 97%.\n",
    "\n",
    "Esto indica que el modelo HMM obtuvo mejores resultados en términos de accuracy en el mismo dataset: tuvo una mayor proporción de predicciones correctas en relación con el total de predicciones en el dataset utilizado.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predecir palabras no existentes en el corpus (dataset de entrenamiento)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Comprovar si el perceptrón estructurado clasifica correctamente una palabra que no ha visto en el entrenamiento.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cacophony'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_seq \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mwalk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mshop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcacophony\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbamboozle\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m new_seq_ids \u001b[39m=\u001b[39m [train_seq\u001b[39m.\u001b[39mx_dict[w] \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m new_seq]\n",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m new_seq \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mwalk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mshop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcacophony\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbamboozle\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m new_seq_ids \u001b[39m=\u001b[39m [train_seq\u001b[39m.\u001b[39;49mx_dict[w] \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m new_seq]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cacophony'"
     ]
    }
   ],
   "source": [
    "new_seq = ['walk', 'shop', 'cacophony', 'bamboozle']\n",
    "new_seq_ids = [train_seq.x_dict[w] for w in new_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bamboozle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m new_seq \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mwalk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mshop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbamboozle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcacophony\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m new_seq_ids  \u001b[39m=\u001b[39m [train_seq\u001b[39m.\u001b[39mx_dict[w] \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m new_seq]\n",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m new_seq \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mwalk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mshop\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mbamboozle\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcacophony\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m new_seq_ids  \u001b[39m=\u001b[39m [train_seq\u001b[39m.\u001b[39;49mx_dict[w] \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m new_seq]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bamboozle'"
     ]
    }
   ],
   "source": [
    "new_seq = ['walk', 'shop', 'bamboozle', 'cacophony']\n",
    "new_seq_ids  = [train_seq.x_dict[w] for w in new_seq]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los errores se deben a que las palabras 'cacophony' y 'bamboozle' no están presentes en el conjunto de datos de entrenamiento. Esto significa que el perceptrón estructurado no ha visto estas palabras durante el entrenamiento y, por lo tanto, no tiene una representación numérica asignada para ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "walk/0 shop/0 bamboozle/0 cacophony/0 "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_seq = skseq.sequences.sequence.Sequence(x=new_seq, \n",
    "                                            y=[int(0) for w in new_seq])\n",
    "new_seq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como las palabra `bamboozle` y `cacophony` no se encuentran en el diccionario construido a partir de las secuencias de entrenamiento, no podemos codificarlos usando el mismo método, pero si podemos trabajar directamente con las palabras y asignar un estado aleatorio `0`. De esta forma, podemos también obtener los features asociados a la secuencia y por lo tanto hacer una predicción del estado asociado también a las nuevas palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0]], [[92], [92], [92]], [[2995]], [[], [], [], []])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# características de la secuencia\n",
    "feature_mapper.get_sequence_features(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk/verb shop/noun bamboozle/noun cacophony/noun '"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decodificación Viterbi para obtener las predicciones de etiquetas para las palabras desconocidas\n",
    "sp.viterbi_decode(new_seq)[0].to_words(test_seq, only_tag_translation=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observamos que el modelo ha predicho correctamente las palabras que estaban en el conjunto de entrenamiento (walk y shop). \n",
    "- Para las nuevas palabras (palabras desconocidas pora el modelo), el modelo ha clasificado bien cacophony como sustantivo, pero ha fallado en el verbo bamboozle, clasificándolo también como sustantivo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
